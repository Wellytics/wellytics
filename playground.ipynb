{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wellytics.api as api\n",
    "import dotenv\n",
    "import time\n",
    "\n",
    "from langchain import OpenAI\n",
    "from wellytics.models import Form, Question, Metric, Response\n",
    "from wellytics.utils import uuid\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map = lambda f, xs: list(map(f, xs))\n",
    "_find = lambda f, xs: next(filter(f, xs), None)\n",
    "_filter = lambda f, xs: list(filter(f, xs))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boostrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Question(BaseModel):\n",
    "#     id: str\n",
    "#     createdAt: int\n",
    "#     updatedAt: int\n",
    "#     type: str\n",
    "#     required: bool\n",
    "#     question: str\n",
    "#     placeholder: Optional[str]\n",
    "#     subQuestions: Optional[List[Dict[str, str]]]\n",
    "#     options: Optional[List[Dict[str, str]]]\n",
    "#     min: Optional[int]\n",
    "#     max: Optional[int]\n",
    "\n",
    "question_template = \"What is your favorite color? {i}\"\n",
    "\n",
    "question_n = 10\n",
    "question_ids = _map(lambda i: f\"question-{i}\", range(question_n))\n",
    "question_texts = _map(lambda i: question_template.format(i=i), range(question_n))\n",
    "question_dicts = [\n",
    "    {\n",
    "        \"id\": id,\n",
    "        \"createdAt\": 0,\n",
    "        \"updatedAt\": 0,\n",
    "        \"type\": \"ShortAnswer\",\n",
    "        \"required\": True,\n",
    "        \"question\": question_texts[i],\n",
    "        \"placeholder\": None,\n",
    "        \"subQuestions\": None,\n",
    "        \"options\": None,\n",
    "        \"min\": None,\n",
    "        \"max\": None,\n",
    "    }\n",
    "    for i, id in enumerate(question_ids)\n",
    "]\n",
    "questions = _map(lambda d: Question(**d), question_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Form(BaseModel):\n",
    "#     id: str\n",
    "#     createdAt: int\n",
    "#     updatedAt: int\n",
    "#     active: bool\n",
    "#     title: str\n",
    "#     description: str\n",
    "#     questions: List[str]  # ref to question\n",
    "\n",
    "form_n = 3\n",
    "form_ids = _map(lambda i: f\"form-{i}\", range(form_n))\n",
    "form_questions_n = 3\n",
    "form_dicts = [\n",
    "    {\n",
    "        \"id\": id,\n",
    "        \"createdAt\": 0,\n",
    "        \"updatedAt\": 0,\n",
    "        \"active\": True,\n",
    "        \"title\": f\"Form {i}\",\n",
    "        \"description\": f\"Form {i} description\",\n",
    "        \"questions\": random.sample(question_ids, form_questions_n),\n",
    "    }\n",
    "    for i, id in enumerate(form_ids)\n",
    "]\n",
    "forms = _map(lambda d: Form(**d), form_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_n = 3\n",
    "tracking_ids = [f\"tracking-{i}\" for i in range(tracking_n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Metric(BaseModel):\n",
    "#     id: str\n",
    "#     createdAt: int\n",
    "#     updatedAt: int\n",
    "#     trackingId: str\n",
    "#     values: Dict[str, float]\n",
    "\n",
    "metric_n = 10\n",
    "metric_values_n = 3\n",
    "metric_value_ids = [f\"metric-value-{i}\" for i in range(metric_values_n)]\n",
    "metric_ids = []\n",
    "metric_dicts = []\n",
    "\n",
    "i = 0\n",
    "for tracking_id in tracking_ids:\n",
    "    for _ in range(metric_n):\n",
    "        id = f\"metric-{i}\"\n",
    "        metric_ids.append(id)\n",
    "        metric_dicts.append(\n",
    "            {\n",
    "                \"id\": id,\n",
    "                \"createdAt\": 0,\n",
    "                \"updatedAt\": 0,\n",
    "                \"trackingId\": tracking_id,\n",
    "                \"values\": {\n",
    "                    metric_value_id: random.random()\n",
    "                    for metric_value_id in metric_value_ids\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "\n",
    "metrics = _map(lambda d: Metric(**d), metric_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Response(BaseModel):\n",
    "#     id: str\n",
    "#     createdAt: int\n",
    "#     updatedAt: int\n",
    "#     formId: str\n",
    "#     trackingId: str\n",
    "#     answers: Dict[str, Union[str, Dict[str, str]]]\n",
    "#     metrics: List[str]  # ref to metric\n",
    "\n",
    "response_n = 10\n",
    "response_metrics_n = 2\n",
    "response_dicts = []\n",
    "\n",
    "i = 0\n",
    "for form_id in form_ids:\n",
    "    for _ in range(response_n):\n",
    "        id = f\"response-{i}\"\n",
    "        tracking_id = random.choice(tracking_ids)\n",
    "        form = _find(lambda f: f.id == form_id, forms)\n",
    "        _metric_ids = [\n",
    "            metric_id\n",
    "            for i, metric_id in enumerate(metric_ids)\n",
    "            if metrics[i].trackingId == tracking_id\n",
    "        ]\n",
    "\n",
    "        response_dict = {\n",
    "            \"id\": id,\n",
    "            \"createdAt\": 0,\n",
    "            \"updatedAt\": 0,\n",
    "            \"formId\": form_id,\n",
    "            \"trackingId\": random.choice(tracking_ids),\n",
    "            \"answers\": {\n",
    "                question_id: random.choice([\"Yes\", \"No\"])\n",
    "                for question_id in form.questions\n",
    "            },\n",
    "            \"metrics\": random.sample(_metric_ids, response_metrics_n),\n",
    "        }\n",
    "\n",
    "        response_dicts.append(response_dict)\n",
    "        i += 1\n",
    "\n",
    "\n",
    "responses = _map(lambda d: Response(**d), response_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    api.create_question(question)\n",
    "\n",
    "for form in forms:\n",
    "    api.create_form(form)\n",
    "\n",
    "for metric in metrics:\n",
    "    api.create_metric(metric)\n",
    "\n",
    "for response in responses:\n",
    "    api.create_response(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_questions()\n",
    "api.get_question(\"question-0\")\n",
    "api.get_forms()\n",
    "api.get_form(\"form-1\")\n",
    "api.get_metrics()\n",
    "api.get_metric(\"metric-0\")\n",
    "api.get_responses(\"form-1\")\n",
    "api.get_response(\"form-1\", \"response-10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_form_metrics(\"form-1\")\n",
    "api.get_response_metrics(\"form-1\", \"response-10\")\n",
    "api.get_tracking(\"tracking-0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_response_analytics(\"form-1\", \"response-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_form_analytics(\"form-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = Question(\n",
    "    id=\"new-question\",\n",
    "    createdAt=0,\n",
    "    updatedAt=0,\n",
    "    type=\"ShortAnswer\",\n",
    "    required=True,\n",
    "    question=\"What is your favorite color?\",\n",
    "    placeholder=None,\n",
    "    subQuestions=None,\n",
    "    options=None,\n",
    "    min=None,\n",
    "    max=None,\n",
    ")\n",
    "api.create_question(question)\n",
    "\n",
    "api.add_question_to_form(\"form-0\", \"new-question\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = Metric(\n",
    "    id=\"new-metric\",\n",
    "    createdAt=0,\n",
    "    updatedAt=0,\n",
    "    trackingId=\"tracking-0\",\n",
    "    values={\"metric-value-0\": 0.5, \"metric-value-1\": 0.5, \"metric-value-2\": 0.5},\n",
    ")\n",
    "api.create_metric(metric)\n",
    "\n",
    "\n",
    "api.add_metric_to_response(\"form-0\", \"response-0\", \"new-metric\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.patch_question(\n",
    "    \"new-question\",\n",
    "    {\n",
    "        \"question\": \"Is this a new question?\",\n",
    "    },\n",
    ")\n",
    "api.patch_form(\n",
    "    \"form-0\",\n",
    "    {\n",
    "        \"title\": \"New title\",\n",
    "    }\n",
    ")\n",
    "api.patch_metric(\n",
    "    \"new-metric\",\n",
    "    {\n",
    "        \"values\": {\"metric-value-0\": 1., \"metric-value-1\": 1.0, \"metric-value-2\": 1.0},\n",
    "    }\n",
    ")\n",
    "api.patch_response(\n",
    "    \"form-0\",\n",
    "    \"response-0\",\n",
    "    {\n",
    "        \"updatedAt\": 1,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.delete_form(\"form-0\")\n",
    "api.delete_response(\"form-0\", \"response-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.set_form_active(\"form-1\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.move_question_up(\"form-1\", \"question-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.move_question_down(\"form-1\", \"question-0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How did you feel before the activity? What were you thinking about? What were you feeling?\",\n",
    "    \"How did you feel during the activity? What were you thinking about? What were you feeling?\",\n",
    "    \"How did you feel after the activity? What were you thinking about? What were you feeling?\",\n",
    "    \"What did you learn about yourself during the activity?\",\n",
    "    \"What did you learn about others during the activity?\",\n",
    "]\n",
    "\n",
    "activity = \"Brothers on The Rise held a field trip for 15 boys to Dimond park to learn about the fish and biodiversity of the park. A park guide guided them through a park trail explaining the park's history and evolutionary impacts observed in the wildlife.\"\n",
    "\n",
    "prompt = \"\"\"Answer the following question based on the description of the activity as if you were a boy (12-19 years old). You are from an underrepresented community and are struggling a lot with several several socioeconomic aspects (e.g., COVID-19, poverty, marginalization, etc).\n",
    "\n",
    "Activity description: {activity_description}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "tracking_n = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = int(time.time())\n",
    "\n",
    "_questions = []\n",
    "for question_text in questions:\n",
    "    question = Question(\n",
    "        id=uuid(),\n",
    "        createdAt=now,\n",
    "        updatedAt=now,\n",
    "        type=\"LongAnswer\",\n",
    "        required=True,\n",
    "        question=question_text,\n",
    "        placeholder=None,\n",
    "        subQuestions=None,\n",
    "        options=None,\n",
    "        min=None,\n",
    "        max=None,\n",
    "    )\n",
    "    api.create_question(question)\n",
    "    _questions.append(question)\n",
    "\n",
    "_form = Form(\n",
    "    id=uuid(),\n",
    "    createdAt=now,\n",
    "    updatedAt=now,\n",
    "    active=True,\n",
    "    title=\"Activity Reflection\",\n",
    "    description=\"This form is used to reflect on an activity.\",\n",
    "    questions=[question.id for question in _questions],\n",
    ")\n",
    "api.create_form(form)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_ids = [uuid() for _ in range(response_n)]\n",
    "\n",
    "_responses = []\n",
    "for i in range(response_n):\n",
    "    now = int(time.time())\n",
    "    answers = {}\n",
    "\n",
    "    for question in _questions:\n",
    "        answers[question.id] = (\n",
    "            llm.generate(\n",
    "                [\n",
    "                    prompt.format(\n",
    "                        activity_description=activity,\n",
    "                        question=question.question,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            .generations[0][0]\n",
    "            .text\n",
    "        )\n",
    "\n",
    "    response = Response(\n",
    "        id=uuid(),\n",
    "        createdAt=now,\n",
    "        updatedAt=now,\n",
    "        formId=_form.id,\n",
    "        trackingId=tracking_ids[i],\n",
    "        answers=answers,\n",
    "        metrics=[],\n",
    "    )\n",
    "    api.create_response(response)\n",
    "    _responses.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_form_analytics(form.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_analytics = api.get_form_analytics(form.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map = lambda f, xs: list(map(f, xs))\n",
    "_find = lambda f, xs: next(filter(f, xs), None)\n",
    "_filter = lambda f, xs: list(filter(f, xs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "questionId = \"659ceb47-dbd9-4a90-982c-2ea6941faf48\"\n",
    "emotions = form_analytics.emotions[questionId]\n",
    "\n",
    "\n",
    "question = _find(lambda question: question.id == questionId, _questions)\n",
    "\n",
    "emotion_labels = [emotion.label for emotion in emotions]\n",
    "y_pos = np.arange(len(emotion_labels))\n",
    "\n",
    "emotion_scores = [emotion.score for emotion in emotions]\n",
    "emotion_random = [random.random() for _ in emotion_labels]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "ax1.bar(y_pos, emotion_random)\n",
    "ax1.set_xticks(y_pos, emotion_labels, rotation=\"vertical\")\n",
    "ax1.set_title(\"(a) Before fine-tuning with domain-specific data\")\n",
    "\n",
    "ax2.bar(y_pos, emotion_scores)\n",
    "ax2.set_xticks(y_pos, emotion_labels, rotation=\"vertical\")\n",
    "ax2.set_title(\"(b) After fine-tuning with domain-specific data\")\n",
    "\n",
    "fig.suptitle(question.question)\n",
    "plt.savefig(\"emotion.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
